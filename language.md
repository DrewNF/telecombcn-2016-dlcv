---
layout: page
title: Language & Vision
permalink: /language
hide: true
---

## Instructor

| ![Xavier Giro-i-Nieto][XavierGiro-photo] |  
|:-:|:-:|:-:|:-:|:-:|:-:|
| [Xavier Giro-i-Nieto (XG)](XavierGiro-web) |

[XavierGiro-web]: https://imatge.upc.edu/web/people/xavier-giro
[XavierGiro-photo]: img/instructors/XavierGiro.jpg "Xavier Giro-i-Nieto"

## Slides

* [Slides](slides/D4L3-language.pdf)

## Video Lecture

(to be added)


## Related Work & Resources

* Karpathy, Andrej, and Li Fei-Fei. ["Deep visual-semantic alignments for generating image descriptions."](http://cs.stanford.edu/people/karpathy/deepimagesent/) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3128-3137. 2015.

* Donahue, Jeffrey, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. ["Long-term recurrent convolutional networks for visual recognition and description."](http://jeffdonahue.com/lrcn/) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2625-2634. 2015.

* Xu, Kelvin, Jimmy Ba, Ryan Kiros, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, and Yoshua Bengio. ["Show, attend and tell: Neural image caption generation with visual attention."](http://kelvinxu.github.io/projects/capgen.html) International Conference for Machine Learning (ICML), 2015.

* Yao, Li, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, and Aaron Courville. ["Describing videos by exploiting temporal structure."](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Yao_Describing_Videos_by_ICCV_2015_paper.html) In Proceedings of the IEEE International Conference on Computer Vision, pp. 4507-4515. 2015. [[code]](https://github.com/yaoli/arctic-capgen-vid)

* Kiros, Ryan, Yukun Zhu, Ruslan R. Salakhutdinov, Richard Zemel, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. ["Skip-thought vectors."](http://papers.nips.cc/paper/5950-skip-thought-vectors) In Advances in Neural Information Processing Systems, pp. 3276-3284. 2015. [[code](https://github.com/ryankiros/skip-thoughts)]

* Mansimov, Elman, Emilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov. ["Generating Images from Captions with Attention."](http://arxiv.org/abs/1511.02793) ICLR 2016. [[code]](http://gitxiv.com/posts/CLLSLp8cprcbpayCn/generating-images-from-captions-with-attention)

* Johnson, Justin, Andrej Karpathy, and Li Fei-Fei. ["DenseCap: Fully Convolutional Localization Networks for Dense Captioning."](https://cs.stanford.edu/people/karpathy/densecap/) CVPR 2016. [[software](https://github.com/jcjohnson/densecap)]

* Elman Mansimov, Emilio Parisotto, Jimmy Ba and Ruslan Salakhutdinov, ["Generating Images from Captions with Attention"](http://arxiv.org/abs/1511.02793). ICLR 2016. [[code](https://github.com/emansim/text2image)]

*  Antol, Stanislaw, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. ["VQA: Visual question answering."](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Antol_VQA_Visual_Question_ICCV_2015_paper.html) In Proceedings of the IEEE International Conference on Computer Vision, pp. 2425-2433. 2015.

* Sadeghi, Fereshteh, Santosh K. Divvala, and Ali Farhadi. ["Viske: Visual knowledge extraction and question answering by visual verification of relation phrases."](http://viske.allenai.org/) CVPR 2015.

* Malinowski, Mateusz, Marcus Rohrbach, and Mario Fritz. ["Ask your neurons: A neural-based approach to answering questions about images."](http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.html) ICCV 2015.

* Xiong, Caiming, Stephen Merity, and Richard Socher. ["Dynamic Memory Networks for Visual and Textual Question Answering."](http://arxiv.org/abs/1603.01417) arXiv preprint arXiv:1603.01417 (2016).

* Ma, Lin, Zhengdong Lu, and Hang Li. ["Learning to answer questions from image using convolutional neural network."](http://arxiv.org/abs/1506.00333) AAAI (2016).

* Zhu, Yuke, Oliver Groth, Michael Bernstein, and Li Fei-Fei. ["Visual7W: Grounded Question Answering in Images."](http://web.stanford.edu/~yukez/visual7w/) CVPR 2016.

* Tapaswi, Makarand, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, and Sanja Fidler. ["MovieQA: Understanding Stories in Movies through Question-Answering."](http://movieqa.cs.toronto.edu/home/) CVPR 2016

* Kim, Jin-Hwa, Sang-Woo Lee, Dong-Hyun Kwak, Min-Oh Heo, Jeonghee Kim, Jung-Woo Ha, and Byoung-Tak Zhang. ["Multimodal Residual Learning for Visual QA."](http://arxiv.org/abs/1606.01455) arXiv preprint arXiv:1606.01455 (2016).

* Mostafazadeh, Nasrin, Ishan Misra, Jacob Devlin, Margaret Mitchell, Xiaodong He, and Lucy Vanderwende. ["Generating Natural Questions About an Image."](http://arxiv.org/abs/1603.06059v3) arXiv preprint arXiv:1603.06059 (2016).

* Ben Bolte, [Deep Language Modeling for Question Answering using Keras](http://benjaminbolte.com/blog/2016/keras-language-modeling.html#recurrent-neural-networks). April 2016.

* Tai, Kai Sheng, Richard Socher, and Christopher D. Manning. ["Improved semantic representations from tree-structured long short-term memory networks."](http://arxiv.org/abs/1503.00075) ACL 2015. [[code](https://github.com/stanfordnlp/treelstm)]
